{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQbHl17rq5C-"
   },
   "outputs": [],
   "source": [
    "from tensorlayerx.nn import Module\n",
    "import tensorlayerx as tlx\n",
    "from tensorlayerx.nn import Conv2d, BatchNorm2d, Elementwise, SubpixelConv2d, UpSampling2d, Flatten, Sequential\n",
    "from tensorlayerx.nn import Linear, MaxPool2d\n",
    "\n",
    "W_init = tlx.initializers.TruncatedNormal(stddev=0.02)\n",
    "G_init = tlx.initializers.TruncatedNormal(mean=1.0, stddev=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcqE5lF5mlgv"
   },
   "source": [
    "## 하이퍼파라미터 조정으로 모델 수정\n",
    "### Conv2d 레이어\n",
    "\n",
    "합성곱 연산을 수행하는 데 사용되는 레이어로, 이미지나 featuring 맵에 커널을 적용하여 새로운 featuring 맵을 생성함.\n",
    "\n",
    "하이퍼파라미터:\n",
    "* out_channels: 출력 채널의 수로, 커널에 대해 생성되는 featuring 맵의 개수를 지정함. 값이 크면 모델이 더 많은 특징을 학습할 수 있지만, 계산 비용이 늘어날 수 있음.\n",
    "* kernel_size: 커널의 크기로, 입력에 적용되는 필터의 크기를 결정함. 작은 크기의 커널은 지역적인 패턴을, 큰 크기의 커널은 더 큰 영역의 패턴을 인식하는 데 유용함.\n",
    "* stride: 필터의 이동 간격을 지정함. 큰 값은 출력 featuring 맵의 크기를 줄이지만, 정보 손실이 발생함. 작은 값은 출력 featuring 맵의 크기를 유지하면서 정보를 보존.\n",
    "* padding: 입력 주변에 더미(zero) 값을 추가하여 출력의 크기를 조절함. \"VALID\"는 패딩 없이 합성곱을 수행하고, \"SAME\"은 패딩을 추가하여 입력과 출력 크기를 동일하게 유지.\n",
    "* act: 활성화 함수를 지정. 일반적으로 \"ReLU\"나 \"LeakyReLU\"와 같은 비선형 활성화 함수를 사용함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwI8PkLKy6tM"
   },
   "source": [
    "### BatchNorm2d 레이어\n",
    "mini batch를 기반으로 입력 데이터의 정규화 수행. 이를 통하여 학습과정을 안정화시키고 학습 속도를 높이며 overfitting 방지\n",
    "\n",
    "하이퍼파라미터:\n",
    "* num_features: 정규화 대상이 되는 입력 채널의 수. Conv2d 레이어의 out_channels값과 일치해야함.\n",
    "* act: 위와 같음\n",
    "* gamma_init: 스케일 파라미터 gamma의 초기화 방법을 지정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYqYuOYIq127"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(Module):\n",
    "    def __init__(self):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = Conv2d(\n",
    "            out_channels=64, kernel_size=(3, 3), stride=(1, 1), act=None, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn1 = BatchNorm2d(num_features=64, act=tlx.ReLU, gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv2 = Conv2d(\n",
    "            out_channels=64, kernel_size=(3, 3), stride=(1, 1), act=None, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn2 = BatchNorm2d(num_features=64, act=None, gamma_init=G_init, data_format='channels_first')\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv1(x)\n",
    "        z = self.bn1(z)\n",
    "        z = self.conv2(z)\n",
    "        z = self.bn2(z)\n",
    "        x = x + z\n",
    "        return x\n",
    "\n",
    "\n",
    "class SRGAN_g(Module):\n",
    "  # 여러 레이어를 순차적으로 연결하여 이미지를 고해상도로 변환하는 generator 클래스\n",
    "    \"\"\" Generator in Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\n",
    "    feature maps (n) and stride (s) feature maps (n) and stride (s)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SRGAN_g, self).__init__()\n",
    "        self.conv1 = Conv2d(\n",
    "            out_channels=64, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first'\n",
    "        )\n",
    "        self.residual_block = self.make_layer()\n",
    "        self.conv2 = Conv2d(\n",
    "            out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn1 = BatchNorm2d(num_features=64, act=None, gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv3 = Conv2d(out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding='SAME', W_init=W_init, data_format='channels_first')\n",
    "        self.subpiexlconv1 = SubpixelConv2d(data_format='channels_first', scale=2, act=tlx.ReLU)\n",
    "        self.conv4 = Conv2d(out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding='SAME', W_init=W_init, data_format='channels_first')\n",
    "        self.subpiexlconv2 = SubpixelConv2d(data_format='channels_first', scale=2, act=tlx.ReLU)\n",
    "        self.conv5 = Conv2d(3, kernel_size=(1, 1), stride=(1, 1), act=tlx.Tanh, padding='SAME', W_init=W_init, data_format='channels_first')\n",
    "\n",
    "    def make_layer(self):\n",
    "        layer_list = []\n",
    "        for i in range(16):\n",
    "            layer_list.append(ResidualBlock())\n",
    "        return Sequential(layer_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        temp = x\n",
    "        x = self.residual_block(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = x + temp\n",
    "        x = self.conv3(x)\n",
    "        x = self.subpiexlconv1(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.subpiexlconv2(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SRGAN_g2(Module):\n",
    "    \"\"\" Generator in Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\n",
    "    feature maps (n) and stride (s) feature maps (n) and stride (s)\n",
    "\n",
    "    96x96 --> 384x384\n",
    "\n",
    "    Use Resize Conv\n",
    "    \"\"\"\n",
    "    #위의 클래스와 비슷하나, SubpixelConv2d가 아닌 UpSampling2d를 이용하여 업샘플링 진행.\n",
    "    #사용자는 둘 중 하나를 선택하여 사용\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SRGAN_g2, self).__init__()\n",
    "        self.conv1 = Conv2d(\n",
    "            out_channels=64, kernel_size=(3, 3), stride=(1, 1), act=None, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first'\n",
    "        )\n",
    "        self.residual_block = self.make_layer()\n",
    "        self.conv2 = Conv2d(\n",
    "            out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn1 = BatchNorm2d(act=None, gamma_init=G_init, data_format='channels_first')\n",
    "\n",
    "        self.upsample1 = UpSampling2d(data_format='channels_first', scale=(2, 2), method='bilinear')\n",
    "        self.conv3 = Conv2d(\n",
    "            out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn2 = BatchNorm2d(act=tlx.ReLU, gamma_init=G_init, data_format='channels_first')\n",
    "\n",
    "        self.upsample2 = UpSampling2d(data_format='channels_first', scale=(4, 4), method='bilinear')\n",
    "        self.conv4 = Conv2d(\n",
    "            out_channels=32, kernel_size=(3, 3), stride=(1, 1), padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn3 = BatchNorm2d(act=tlx.ReLU, gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv5 = Conv2d(\n",
    "            out_channels=3, kernel_size=(1, 1), stride=(1, 1), act=tlx.Tanh, padding='SAME', W_init=W_init\n",
    "        )\n",
    "\n",
    "    def make_layer(self):\n",
    "        layer_list = []\n",
    "        for i in range(16):\n",
    "            layer_list.append(ResidualBlock())\n",
    "        return Sequential(layer_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        temp = x\n",
    "        x = self.residual_block(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = x + temp\n",
    "        x = self.upsample1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.upsample2(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv5(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SRGAN_d2(Module):\n",
    "    \"\"\" Discriminator in Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\n",
    "    feature maps (n) and stride (s) feature maps (n) and stride (s)\n",
    "    \"\"\"\n",
    "    #이미지를 고해상도와 저해상도로 구분하는 판별기 클래스\n",
    "    #총 8개의 Conv2d, 7개의 BatchNorm2d 레이어 사용\n",
    "    #Elementwise 레이어 사용 x\n",
    "    #Flatten, linear 레이어로 끝남.\n",
    "\n",
    "\n",
    "    def __init__(self, ):\n",
    "        super(SRGAN_d2, self).__init__()\n",
    "        self.conv1 = Conv2d(\n",
    "            out_channels=64, kernel_size=(3, 3), stride=(1, 1), act=tlx.LeakyReLU(negative_slope=0.2), padding='SAME',\n",
    "            W_init=W_init, data_format='channels_first'\n",
    "        )\n",
    "        self.conv2 = Conv2d(\n",
    "            out_channels=64, kernel_size=(3, 3), stride=(2, 2), act=tlx.LeakyReLU(negative_slope=0.2), padding='SAME',\n",
    "            W_init=W_init, data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn1 = BatchNorm2d(gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv3 = Conv2d(\n",
    "            out_channels=128, kernel_size=(3, 3), stride=(1, 1), act=tlx.LeakyReLU(negative_slope=0.2), padding='SAME',\n",
    "            W_init=W_init, data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn2 = BatchNorm2d(gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv4 = Conv2d(\n",
    "            out_channels=128, kernel_size=(3, 3), stride=(2, 2), act=tlx.LeakyReLU(negative_slope=0.2), padding='SAME',\n",
    "            W_init=W_init, data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn3 = BatchNorm2d(gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv5 = Conv2d(\n",
    "            out_channels=256, kernel_size=(3, 3), stride=(1, 1), act=tlx.LeakyReLU(negative_slope=0.2), padding='SAME',\n",
    "            W_init=W_init, data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn4 = BatchNorm2d(gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv6 = Conv2d(\n",
    "            out_channels=256, kernel_size=(3, 3), stride=(2, 2), act=tlx.LeakyReLU(negative_slope=0.2), padding='SAME',\n",
    "            W_init=W_init, data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn5 = BatchNorm2d(gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv7 = Conv2d(\n",
    "            out_channels=512, kernel_size=(3, 3), stride=(1, 1), act=tlx.LeakyReLU(negative_slope=0.2), padding='SAME',\n",
    "            W_init=W_init, data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn6 = BatchNorm2d(gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv8 = Conv2d(\n",
    "            out_channels=512, kernel_size=(3, 3), stride=(2, 2), act=tlx.LeakyReLU(negative_slope=0.2), padding='SAME',\n",
    "            W_init=W_init, data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn7 = BatchNorm2d(gamma_init=G_init, data_format='channels_first')\n",
    "        self.flat = Flatten()\n",
    "        self.dense1 = Linear(out_features=1024, act=tlx.LeakyReLU(negative_slope=0.2))\n",
    "        self.dense2 = Linear(out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.bn7(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        logits = x\n",
    "        n = tlx.sigmoid(x)\n",
    "        return n, logits\n",
    "\n",
    "\n",
    "class SRGAN_d(Module):\n",
    "  #위 클래스와 비슷하나, 더 많은 레이어, 깊은 구조를 가짐. 사용자는 둘 중 하나를 선택하여 사용\n",
    "  #이미지를 고해상도와 저해상도로 구분하는 판별기 클래스\n",
    "  #총 8개의 Conv2d, 7개의 BatchNorm2d 레이어 사용\n",
    "  #Elementwise 레이어 사용 x\n",
    "  #Flatten 레이어 1개와\n",
    "\n",
    "    def __init__(self, dim=64):\n",
    "        super(SRGAN_d, self).__init__()\n",
    "        self.conv1 = Conv2d(\n",
    "            out_channels=dim, kernel_size=(4, 4), stride=(2, 2), act=tlx.LeakyReLU, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first'\n",
    "        )\n",
    "        self.conv2 = Conv2d(\n",
    "            out_channels=dim * 2, kernel_size=(4, 4), stride=(2, 2), act=None, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn1 = BatchNorm2d(num_features=dim * 2, act=tlx.LeakyReLU, gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv3 = Conv2d(\n",
    "            out_channels=dim * 4, kernel_size=(4, 4), stride=(2, 2), act=None, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn2 = BatchNorm2d(num_features=dim * 4, act=tlx.LeakyReLU, gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv4 = Conv2d(\n",
    "            out_channels=dim * 8, kernel_size=(4, 4), stride=(2, 2), act=None, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn3 = BatchNorm2d(num_features=dim * 8, act=tlx.LeakyReLU, gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv5 = Conv2d(\n",
    "            out_channels=dim * 16, kernel_size=(4, 4), stride=(2, 2), act=None, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn4 = BatchNorm2d(num_features=dim * 16, act=tlx.LeakyReLU, gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv6 = Conv2d(\n",
    "            out_channels=dim * 32, kernel_size=(4, 4), stride=(2, 2), act=None, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn5 = BatchNorm2d(num_features=dim * 32, act=tlx.LeakyReLU, gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv7 = Conv2d(\n",
    "            out_channels=dim * 16, kernel_size=(1, 1), stride=(1, 1), act=None, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn6 = BatchNorm2d(num_features=dim * 16, act=tlx.LeakyReLU, gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv8 = Conv2d(\n",
    "            out_channels=dim * 8, kernel_size=(1, 1), stride=(1, 1), act=None, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn7 = BatchNorm2d(num_features=dim * 8, act=None, gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv9 = Conv2d(\n",
    "            out_channels=dim * 2, kernel_size=(1, 1), stride=(1, 1), act=None, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn8 = BatchNorm2d(num_features=dim * 2, act=tlx.LeakyReLU, gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv10 = Conv2d(\n",
    "            out_channels=dim * 2, kernel_size=(3, 3), stride=(1, 1), act=None, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn9 = BatchNorm2d(num_features=dim * 2, act=tlx.LeakyReLU, gamma_init=G_init, data_format='channels_first')\n",
    "        self.conv11 = Conv2d(\n",
    "            out_channels=dim * 8, kernel_size=(3, 3), stride=(1, 1), act=None, padding='SAME', W_init=W_init,\n",
    "            data_format='channels_first', b_init=None\n",
    "        )\n",
    "        self.bn10 = BatchNorm2d(num_features=dim * 8, gamma_init=G_init, data_format='channels_first')\n",
    "        self.add = Elementwise(combine_fn=tlx.add, act=tlx.LeakyReLU)\n",
    "        self.flat = Flatten()\n",
    "        self.dense = Linear(out_features=1, W_init=W_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.bn7(x)\n",
    "        temp = x\n",
    "        x = self.conv9(x)\n",
    "        x = self.bn8(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.bn9(x)\n",
    "        x = self.conv11(x)\n",
    "        x = self.bn10(x)\n",
    "        x = self.add([temp, x])\n",
    "        x = self.flat(x)\n",
    "        x = self.dense(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9WrJjEHqvHW"
   },
   "outputs": [],
   "source": [
    "class Vgg19_simple_api(Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Vgg19_simple_api, self).__init__()\n",
    "        \"\"\" conv1 \"\"\"\n",
    "        self.conv1 = Conv2d(out_channels=64, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.conv2 = Conv2d(out_channels=64, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding='SAME')\n",
    "        \"\"\" conv2 \"\"\"\n",
    "        self.conv3 = Conv2d(out_channels=128, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.conv4 = Conv2d(out_channels=128, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding='SAME')\n",
    "        \"\"\" conv3 \"\"\"\n",
    "        self.conv5 = Conv2d(out_channels=256, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.conv6 = Conv2d(out_channels=256, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.conv7 = Conv2d(out_channels=256, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.conv8 = Conv2d(out_channels=256, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.maxpool3 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding='SAME')\n",
    "        \"\"\" conv4 \"\"\"\n",
    "        self.conv9 = Conv2d(out_channels=512, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.conv10 = Conv2d(out_channels=512, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.conv11 = Conv2d(out_channels=512, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.conv12 = Conv2d(out_channels=512, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.maxpool4 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding='SAME')  # (batch_size, 14, 14, 512)\n",
    "        \"\"\" conv5 \"\"\"\n",
    "        self.conv13 = Conv2d(out_channels=512, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.conv14 = Conv2d(out_channels=512, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.conv15 = Conv2d(out_channels=512, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.conv16 = Conv2d(out_channels=512, kernel_size=(3, 3), stride=(1, 1), act=tlx.ReLU, padding='SAME')\n",
    "        self.maxpool5 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding='SAME')  # (batch_size, 7, 7, 512)\n",
    "        \"\"\" fc 6~8 \"\"\"\n",
    "        self.flat = Flatten()\n",
    "        self.dense1 = Linear(out_features=4096, act=tlx.ReLU)\n",
    "        self.dense2 = Linear(out_features=4096, act=tlx.ReLU)\n",
    "        self.dense3 = Linear(out_features=1000, act=tlx.identity)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.conv11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.maxpool4(x)\n",
    "        conv = x\n",
    "        x = self.conv13(x)\n",
    "        x = self.conv14(x)\n",
    "        x = self.conv15(x)\n",
    "        x = self.conv16(x)\n",
    "        x = self.maxpool5(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return x, conv"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
